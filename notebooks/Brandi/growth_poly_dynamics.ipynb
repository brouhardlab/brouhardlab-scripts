{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93466b1-4a47-4ff6-a571-7951d42e36e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from read_roi import read_roi_zip\n",
    "from collections import OrderedDict, Counter\n",
    "import math\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL.TiffTags import TAGS\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a4096a-9317-47df-a59a-26fa5845f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "askdirectory = filedialog.askdirectory() # show an \"Open\" dialog box and return the path to the selected file\n",
    "path = Path(askdirectory)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180a4227-736d-4204-b70f-ea699d69ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tubulin = '[Tubulin] ' r'$(\\mu M)$'\n",
    "tub = 'tub'\n",
    "\n",
    "DCXconc = '[DCX] ' r'$(n M)$'\n",
    "DCX = 'DCX'\n",
    "\n",
    "investigator = 'Brandi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd01de7-a3f9-4156-bea3-9926767374ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dateloc = str(path).find(\"202\")\n",
    "date = str(path)[dateloc : dateloc+10]\n",
    "\n",
    "folders = [x for x in path.iterdir() if x.is_dir()]\n",
    "folders = [i for i in folders if (str(i)[-5:] == 'final') == True]\n",
    "\n",
    "ch = []\n",
    "conc_tub = []\n",
    "conc_DCX = []\n",
    "DCX_type = []\n",
    "\n",
    "for i in folders:\n",
    "    CHloc = str(i).rfind(\"Ch\")\n",
    "    tubloc = str(i).rfind(tub)\n",
    "    ch = ch + [str(i)[CHloc+2:CHloc+3]]\n",
    "    conc_tub = conc_tub + [(str(i)[tubloc+3:tubloc+5])]\n",
    "    \n",
    "\n",
    "date,ch, conc_tub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439965eb-da4d-421e-9a93-027728f699a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tub_conc =  [float(i) for i in conc_tub]\n",
    "frame_analyzer = pd.read_csv(path/'frame_rates_avg.csv',sep=',')\n",
    "pixel =  0.107 #T2 0.107 #T1 0.0633\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5bfa14-059f-4f9b-99bc-a1a2590c4793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frame_analyzer = frame_analyzer.iloc[[1,3]].reset_index()\n",
    "frame_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2cfb89-3611-4286-b196-6f08d1b6bab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_roi_poly(k,name):\n",
    "    roi_path = folders[k]/(name)\n",
    "\n",
    "    roi_data = read_roi_zip(roi_path)\n",
    "    roi_df = pd.DataFrame(columns=['Track ID','x1','x2','x3','y1','y2','y3'])\n",
    "    \n",
    "    for key in roi_data:\n",
    "        roi_df1 = pd.DataFrame({'Track ID': [roi_data[key]['name']],'x1': [roi_data[key]['x'][0]],'x2': [roi_data[key]['x'][1]],'x3': [roi_data[key]['x'][2]],'y1': [roi_data[key]['y'][0]],'y2': [roi_data[key]['y'][1]],'y3': [roi_data[key]['y'][2]]})\n",
    "        roi_df = pd.concat([roi_df,roi_df1])\n",
    "    \n",
    "    roi_df = roi_df.reset_index(drop = True)\n",
    "    return roi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6974db2-b80e-43cc-9b3c-8a0f1f61ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_path = folders[0]/('start.zip')\n",
    "roi_data = read_roi_zip(roi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1e88e2-f14e-4d32-9db8-5e8724672dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Length = 'Length ' r'$(\\mu m)$'\n",
    "Lifetime = 'Lifetime ' r'$(min)$'\n",
    "GrowthRate = 'Growth Rate ' r'$(\\mu m / min)$'\n",
    "TimeToNucleate = 'Time to Nucleate ' r'$(min)$'\n",
    "ShrinkageLength = 'Shrink Length ' r'$(\\mu m)$'\n",
    "ShrinkageLifetime = 'Shrink Lifetime ' r'$(min)$'\n",
    "ShrinkageRate = 'Shrink Rate ' r'$(\\mu m / min)$'\n",
    "poly_parameter_names = (Length,Lifetime,GrowthRate,TimeToNucleate)\n",
    "line_parameter_names = (Length,Lifetime,GrowthRate,TimeToNucleate,ShrinkageLength,ShrinkageLifetime,ShrinkageRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d6aea6-c1b3-45e0-bbd2-b4165485aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_dynamics(k):\n",
    "        \n",
    "    data = open_roi_poly(k,'kymoslopes.zip')\n",
    "    supp = open_roi_poly(k,'start.zip')\n",
    "    \n",
    "    spf = frame_analyzer['Mean'][k];\n",
    "    frames = frame_analyzer['Frames'][k]\n",
    "    \n",
    "    suppn = len(supp)\n",
    "    start = sum(abs(supp['y2']-supp['y1']))/suppn;\n",
    "    \n",
    "    n = len(data)\n",
    "    pre_df = {'Date': np.full((n), date), 'Investigator': np.full((n), investigator),\n",
    "              'Ch': np.full((n), ch[k]),tubulin: np.full((n), tub_conc[k])}\n",
    "    df = pd.DataFrame(pre_df) \n",
    "    \n",
    "    df[Length] = abs((data['x2']-data['x1'])*pixel)\n",
    "    data[Lifetime] = abs((data['y2']-data['y1'])*spf/60)\n",
    "    \n",
    "    df[Lifetime] = data[[Lifetime,'y2']].apply(lambda x: x[Lifetime] if x['y2'] < frames else np.NaN, axis=1)\n",
    "    df[Lifetime] = data[[Lifetime,'y2']].apply(lambda x: x[Lifetime] if x[Lifetime] != 0 else np.NaN, axis=1)\n",
    "    \n",
    "    df[GrowthRate] = df[Length]/df[Lifetime]\n",
    "    df[GrowthRate] = df[GrowthRate].apply(lambda x: x if x <= 5 else np.NAN )\n",
    "    \n",
    "    df[TimeToNucleate] = (data['y1']-start)*spf/60\n",
    "    \n",
    "    df[ShrinkageLength] = abs((data['x3']-data['x2'])*pixel)\n",
    "    df[ShrinkageLifetime] = abs((data['y3']-data['y2'])*spf/60)\n",
    "    df[ShrinkageLifetime] = df[ShrinkageLifetime].apply(lambda x: np.NAN if x == 0 else x)\n",
    "    df[ShrinkageRate] = df[ShrinkageLength]/df[ShrinkageLifetime]\n",
    "    \n",
    "    df.loc[pd.isnull(df[GrowthRate]), \n",
    "           [Length,Lifetime,TimeToNucleate,ShrinkageLength,ShrinkageLifetime,ShrinkageRate]] = np.NaN\n",
    "    \n",
    "    df['Rescues'] = df[[Length,ShrinkageLength]].apply(lambda x: True if abs(x[Length]-x[ShrinkageLength]) > pixel*5 else False, axis=1)\n",
    "    \n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2065186e-9f45-4411-8875-953354562031",
   "metadata": {},
   "outputs": [],
   "source": [
    "path.parents[0],path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a40ba0a-e746-47c5-b121-3e62ed469efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdirectory = str(path.parents[0])+'//Data_Sheets'\n",
    "# newmydir = Path(newdirectory)\n",
    "# newmydir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7100c303-216d-4a16-b314-c2b1a1fff481",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = poly_dynamics(0)\n",
    "for i in range(1,len(ch)):\n",
    "    df0 = poly_dynamics(i)\n",
    "    df = df.append(df0, ignore_index=True)\n",
    "\n",
    "df.to_csv(path/(investigator+'_'+date +'.csv'), encoding='utf-8', index=False)\n",
    "#df.to_csv(newmydir/(investigator+'_'+date+'.csv'), encoding='utf-8', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27d3e69-da59-4bae-9288-01c1eaac73ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmean = df.groupby('Ch').mean()\n",
    "dfmean.to_csv(path/(date+'_0_mean.csv'), encoding='utf-8', index=False)\n",
    "dfmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac89447e-9205-465e-a139-c19ca0b742c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfstd = df.groupby('Ch').std()\n",
    "dfstd.to_csv(path/(date+'_0_std.csv'), encoding='utf-8', index=False)\n",
    "dfstd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
